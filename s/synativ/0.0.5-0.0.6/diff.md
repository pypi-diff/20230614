# Comparing `tmp/synativ-0.0.5-py3-none-any.whl.zip` & `tmp/synativ-0.0.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,23 +1,23 @@
-Zip file size: 11245 bytes, number of entries: 21
--rw-r--r--  2.0 unx      400 b- defN 23-Jun-13 13:47 synativ/__init__.py
--rw-r--r--  2.0 unx    11693 b- defN 23-Jun-13 13:47 synativ/client.py
--rw-r--r--  2.0 unx     1191 b- defN 23-Jun-13 13:47 synativ/dataset_utils.py
--rw-r--r--  2.0 unx      195 b- defN 23-Jun-13 13:47 synativ/environment.py
--rw-r--r--  2.0 unx      348 b- defN 23-Jun-13 13:47 synativ/core/__init__.py
--rw-r--r--  2.0 unx      426 b- defN 23-Jun-13 13:47 synativ/core/api_error.py
--rw-r--r--  2.0 unx     1047 b- defN 23-Jun-13 13:47 synativ/core/datetime_utils.py
--rw-r--r--  2.0 unx     3710 b- defN 23-Jun-13 13:47 synativ/core/jsonable_encoder.py
--rw-r--r--  2.0 unx      385 b- defN 23-Jun-13 13:47 synativ/core/remove_none_from_headers.py
--rw-r--r--  2.0 unx      451 b- defN 23-Jun-13 13:47 synativ/types/__init__.py
--rw-r--r--  2.0 unx      862 b- defN 23-Jun-13 13:47 synativ/types/dataset.py
--rw-r--r--  2.0 unx      779 b- defN 23-Jun-13 13:47 synativ/types/dataset_dataset_params.py
--rw-r--r--  2.0 unx      764 b- defN 23-Jun-13 13:47 synativ/types/dataset_ids.py
--rw-r--r--  2.0 unx      827 b- defN 23-Jun-13 13:47 synativ/types/model.py
--rw-r--r--  2.0 unx      760 b- defN 23-Jun-13 13:47 synativ/types/model_ids.py
--rw-r--r--  2.0 unx      810 b- defN 23-Jun-13 13:47 synativ/types/model_model_params.py
--rw-r--r--  2.0 unx      755 b- defN 23-Jun-13 13:47 synativ/types/presigned_url.py
--rw-r--r--  2.0 unx     1299 b- defN 23-Jun-13 13:47 synativ-0.0.5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-13 13:47 synativ-0.0.5.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-Jun-13 13:47 synativ-0.0.5.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1716 b- defN 23-Jun-13 13:47 synativ-0.0.5.dist-info/RECORD
-21 files, 28518 bytes uncompressed, 8447 bytes compressed:  70.4%
+Zip file size: 11250 bytes, number of entries: 21
+-rw-r--r--  2.0 unx      400 b- defN 23-Jun-14 09:07 synativ/__init__.py
+-rw-r--r--  2.0 unx    11749 b- defN 23-Jun-14 09:07 synativ/client.py
+-rw-r--r--  2.0 unx     1191 b- defN 23-Jun-14 09:07 synativ/dataset_utils.py
+-rw-r--r--  2.0 unx      195 b- defN 23-Jun-14 09:07 synativ/environment.py
+-rw-r--r--  2.0 unx      348 b- defN 23-Jun-14 09:07 synativ/core/__init__.py
+-rw-r--r--  2.0 unx      426 b- defN 23-Jun-14 09:07 synativ/core/api_error.py
+-rw-r--r--  2.0 unx     1047 b- defN 23-Jun-14 09:07 synativ/core/datetime_utils.py
+-rw-r--r--  2.0 unx     3710 b- defN 23-Jun-14 09:07 synativ/core/jsonable_encoder.py
+-rw-r--r--  2.0 unx      385 b- defN 23-Jun-14 09:07 synativ/core/remove_none_from_headers.py
+-rw-r--r--  2.0 unx      451 b- defN 23-Jun-14 09:07 synativ/types/__init__.py
+-rw-r--r--  2.0 unx      862 b- defN 23-Jun-14 09:07 synativ/types/dataset.py
+-rw-r--r--  2.0 unx      779 b- defN 23-Jun-14 09:07 synativ/types/dataset_dataset_params.py
+-rw-r--r--  2.0 unx      764 b- defN 23-Jun-14 09:07 synativ/types/dataset_ids.py
+-rw-r--r--  2.0 unx      827 b- defN 23-Jun-14 09:07 synativ/types/model.py
+-rw-r--r--  2.0 unx      760 b- defN 23-Jun-14 09:07 synativ/types/model_ids.py
+-rw-r--r--  2.0 unx      810 b- defN 23-Jun-14 09:07 synativ/types/model_model_params.py
+-rw-r--r--  2.0 unx      755 b- defN 23-Jun-14 09:07 synativ/types/presigned_url.py
+-rw-r--r--  2.0 unx     1299 b- defN 23-Jun-14 09:07 synativ-0.0.6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-14 09:07 synativ-0.0.6.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Jun-14 09:07 synativ-0.0.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1716 b- defN 23-Jun-14 09:07 synativ-0.0.6.dist-info/RECORD
+21 files, 28574 bytes uncompressed, 8452 bytes compressed:  70.4%
```

## zipnote {}

```diff
@@ -45,20 +45,20 @@
 
 Filename: synativ/types/model_model_params.py
 Comment: 
 
 Filename: synativ/types/presigned_url.py
 Comment: 
 
-Filename: synativ-0.0.5.dist-info/METADATA
+Filename: synativ-0.0.6.dist-info/METADATA
 Comment: 
 
-Filename: synativ-0.0.5.dist-info/WHEEL
+Filename: synativ-0.0.6.dist-info/WHEEL
 Comment: 
 
-Filename: synativ-0.0.5.dist-info/top_level.txt
+Filename: synativ-0.0.6.dist-info/top_level.txt
 Comment: 
 
-Filename: synativ-0.0.5.dist-info/RECORD
+Filename: synativ-0.0.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## synativ/client.py

```diff
@@ -22,15 +22,15 @@
         self._environment = environment
         self.api_key = api_key
 
     def list_datasets(self) -> DatasetIds:
         _response = httpx.request(
             "GET",
             urllib.parse.urljoin(f"{self._environment.value}/", "v1/datasets"),
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(DatasetIds, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -38,30 +38,30 @@
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     def create_dataset(self, *, dataset_name: str) -> Dataset:
         _response = httpx.request(
             "POST",
             urllib.parse.urljoin(f"{self._environment.value}/", "v1/datasets"),
             json=jsonable_encoder({"dataset_name": dataset_name}),
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
             raise ApiError(status_code=_response.status_code, body=_response.text)
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     def get_dataset(self, dataset_id: str) -> Dataset:
         _response = httpx.request(
             "GET",
             urllib.parse.urljoin(f"{self._environment.value}/", f"v1/datasets/{dataset_id}"),
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -69,30 +69,30 @@
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     def get_upload_url(self, dataset_id: str, *, filename: str) -> PresignedUrl:
         _response = httpx.request(
             "GET",
             urllib.parse.urljoin(f"{self._environment.value}/", f"v1/datasets/{dataset_id}/uploadurl"),
             params={"filename": filename},
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
             raise ApiError(status_code=_response.status_code, body=_response.text)
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     def list_models(self) -> ModelIds:
         _response = httpx.request(
             "GET",
             urllib.parse.urljoin(f"{self._environment.value}/", "v1/models"),
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(ModelIds, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -100,30 +100,30 @@
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     def create_model(self, *, base_model: str, dataset_id: str) -> Model:
         _response = httpx.request(
             "POST",
             urllib.parse.urljoin(f"{self._environment.value}/", "v1/models"),
             json=jsonable_encoder({"base_model": base_model, "dataset_id": dataset_id}),
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Model, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
             raise ApiError(status_code=_response.status_code, body=_response.text)
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     def get_model(self, model_id: str) -> Model:
         _response = httpx.request(
             "GET",
             urllib.parse.urljoin(f"{self._environment.value}/", f"v1/models/{model_id}"),
-            headers=remove_none_from_headers({"x-api-key": self.api_key}),
+            headers=remove_none_from_headers({"Authorization": self.api_key}),
             timeout=60,
         )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Model, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -137,15 +137,15 @@
         self.api_key = api_key
 
     async def list_datasets(self) -> DatasetIds:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "GET",
                 urllib.parse.urljoin(f"{self._environment.value}/", "v1/datasets"),
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(DatasetIds, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -154,15 +154,15 @@
 
     async def create_dataset(self, *, dataset_name: str) -> Dataset:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "POST",
                 urllib.parse.urljoin(f"{self._environment.value}/", "v1/datasets"),
                 json=jsonable_encoder({"dataset_name": dataset_name}),
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -170,15 +170,15 @@
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     async def get_dataset(self, dataset_id: str) -> Dataset:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "GET",
                 urllib.parse.urljoin(f"{self._environment.value}/", f"v1/datasets/{dataset_id}"),
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -187,15 +187,15 @@
 
     async def get_upload_url(self, dataset_id: str, *, filename: str) -> PresignedUrl:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "GET",
                 urllib.parse.urljoin(f"{self._environment.value}/", f"v1/datasets/{dataset_id}/uploadurl"),
                 params={"filename": filename},
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -203,15 +203,15 @@
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     async def list_models(self) -> ModelIds:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "GET",
                 urllib.parse.urljoin(f"{self._environment.value}/", "v1/models"),
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(ModelIds, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -220,15 +220,15 @@
 
     async def create_model(self, *, base_model: str, dataset_id: str) -> Model:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "POST",
                 urllib.parse.urljoin(f"{self._environment.value}/", "v1/models"),
                 json=jsonable_encoder({"base_model": base_model, "dataset_id": dataset_id}),
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Model, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
@@ -236,15 +236,15 @@
         raise ApiError(status_code=_response.status_code, body=_response_json)
 
     async def get_model(self, model_id: str) -> Model:
         async with httpx.AsyncClient() as _client:
             _response = await _client.request(
                 "GET",
                 urllib.parse.urljoin(f"{self._environment.value}/", f"v1/models/{model_id}"),
-                headers=remove_none_from_headers({"x-api-key": self.api_key}),
+                headers=remove_none_from_headers({"Authorization": self.api_key}),
                 timeout=60,
             )
         if 200 <= _response.status_code < 300:
             return pydantic.parse_obj_as(Model, _response.json())  # type: ignore
         try:
             _response_json = _response.json()
         except JSONDecodeError:
```

## Comparing `synativ-0.0.5.dist-info/METADATA` & `synativ-0.0.6.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: synativ
-Version: 0.0.5
+Version: 0.0.6
 Summary: Synativ Computer Vision Toolbox
 Home-page: https://synativ.com
 Author: SYNATIV TECHNOLOGIES LTD
 Author-email: info@synativ.com
 License: Apache Software License (http://www.apache.org/licenses/LICENSE-2.0)
 Description-Content-Type: text/markdown
 Requires-Dist: pydantic (==1.10.9)
```

## Comparing `synativ-0.0.5.dist-info/RECORD` & `synativ-0.0.6.dist-info/RECORD`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 synativ/__init__.py,sha256=8Z2d1JWhXirw86-50Fj9PNuFefNSacNR9NrLhH5YH9g,400
-synativ/client.py,sha256=kXSq8Q0dDkORqVgZtu_VxCgGJhRppDyGGcenhyAjztQ,11693
+synativ/client.py,sha256=x6eDTqdTmU2Q-ugkidx8e4Zzduu5hkaqOlhtwNyMefs,11749
 synativ/dataset_utils.py,sha256=pCgPRNMERkbQMTWnubEIMlQ4aqU41HQcL50vSW2jgUM,1191
 synativ/environment.py,sha256=ipQS69A2sQr2FvZIaxW783DciU8B0sLSTdrEkIhY8LY,195
 synativ/core/__init__.py,sha256=qQP1ec3_wC4q9KA3hqDEqyllC-z5Bza2NPQbADBq5f8,348
 synativ/core/api_error.py,sha256=RE8LELok2QCjABadECTvtDp7qejA1VmINCh6TbqPwSE,426
 synativ/core/datetime_utils.py,sha256=nBys2IsYrhPdszxGKCNRPSOCwa-5DWOHG95FB8G9PKo,1047
 synativ/core/jsonable_encoder.py,sha256=yHrx0C19n1H77G-GanO-HsFyBPVMlsJz7WffsHwXEVI,3710
 synativ/core/remove_none_from_headers.py,sha256=paKMgUVWJW133a_5y5lV00bhOuZOgZqWrON_oGNuzCA,385
@@ -11,11 +11,11 @@
 synativ/types/dataset.py,sha256=SAtO5T9q_wDlmhawwrGoyuNjIMfooEEhGtHfbZc3bSk,862
 synativ/types/dataset_dataset_params.py,sha256=2GDHEjPPuOAu88jVNrxkCQY4fJ5wqr3EVTZQI0ypStI,779
 synativ/types/dataset_ids.py,sha256=fAb9ZZvEQPhlTKLmeuXZUQ2Le2NVQ3_jO318kMY_-gI,764
 synativ/types/model.py,sha256=iPFlOmRhThcNz_9QkQJk5HVntoZNYUmOAvk-hMFgQIw,827
 synativ/types/model_ids.py,sha256=1VKkx5NuR2VBl7QjYdeBSUag2TV0frXo6jy9Tl2GO6E,760
 synativ/types/model_model_params.py,sha256=Yt0834tBiJY1ON5tAgqnBrT8J1pFFi16-juhezq5o5I,810
 synativ/types/presigned_url.py,sha256=baDPHUEpZVJvj8Q_tO1rOmnjtRPwSzp57apb2rkVtWA,755
-synativ-0.0.5.dist-info/METADATA,sha256=uMZSOq7MDohbPC_Sr1048lyW3WwXuzbWgKcwK4F-y_U,1299
-synativ-0.0.5.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-synativ-0.0.5.dist-info/top_level.txt,sha256=8S-EjjWP2xP0t8f-Na0kJVrl7uU8O-XcLzBMUy6Q5v8,8
-synativ-0.0.5.dist-info/RECORD,,
+synativ-0.0.6.dist-info/METADATA,sha256=0PJur9N1IDwMBARALcRyJD0Jd1kX-hU0o8NGfVk09HM,1299
+synativ-0.0.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+synativ-0.0.6.dist-info/top_level.txt,sha256=8S-EjjWP2xP0t8f-Na0kJVrl7uU8O-XcLzBMUy6Q5v8,8
+synativ-0.0.6.dist-info/RECORD,,
```

